{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a8d37c",
   "metadata": {},
   "source": [
    "#### Class Week 15\n",
    "\n",
    "###### Warm-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd684caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f59881",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.arange(1,1001,1)\n",
    "even_values = []\n",
    "\n",
    "for x in values:\n",
    "    if x%2 == 0:\n",
    "        even_values.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0feef190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 14,\n",
       " 16,\n",
       " 18,\n",
       " 20,\n",
       " 22,\n",
       " 24,\n",
       " 26,\n",
       " 28,\n",
       " 30,\n",
       " 32,\n",
       " 34,\n",
       " 36,\n",
       " 38,\n",
       " 40,\n",
       " 42,\n",
       " 44,\n",
       " 46,\n",
       " 48,\n",
       " 50,\n",
       " 52,\n",
       " 54,\n",
       " 56,\n",
       " 58,\n",
       " 60,\n",
       " 62,\n",
       " 64,\n",
       " 66,\n",
       " 68,\n",
       " 70,\n",
       " 72,\n",
       " 74,\n",
       " 76,\n",
       " 78,\n",
       " 80,\n",
       " 82,\n",
       " 84,\n",
       " 86,\n",
       " 88,\n",
       " 90,\n",
       " 92,\n",
       " 94,\n",
       " 96,\n",
       " 98,\n",
       " 100,\n",
       " 102,\n",
       " 104,\n",
       " 106,\n",
       " 108,\n",
       " 110,\n",
       " 112,\n",
       " 114,\n",
       " 116,\n",
       " 118,\n",
       " 120,\n",
       " 122,\n",
       " 124,\n",
       " 126,\n",
       " 128,\n",
       " 130,\n",
       " 132,\n",
       " 134,\n",
       " 136,\n",
       " 138,\n",
       " 140,\n",
       " 142,\n",
       " 144,\n",
       " 146,\n",
       " 148,\n",
       " 150,\n",
       " 152,\n",
       " 154,\n",
       " 156,\n",
       " 158,\n",
       " 160,\n",
       " 162,\n",
       " 164,\n",
       " 166,\n",
       " 168,\n",
       " 170,\n",
       " 172,\n",
       " 174,\n",
       " 176,\n",
       " 178,\n",
       " 180,\n",
       " 182,\n",
       " 184,\n",
       " 186,\n",
       " 188,\n",
       " 190,\n",
       " 192,\n",
       " 194,\n",
       " 196,\n",
       " 198,\n",
       " 200,\n",
       " 202,\n",
       " 204,\n",
       " 206,\n",
       " 208,\n",
       " 210,\n",
       " 212,\n",
       " 214,\n",
       " 216,\n",
       " 218,\n",
       " 220,\n",
       " 222,\n",
       " 224,\n",
       " 226,\n",
       " 228,\n",
       " 230,\n",
       " 232,\n",
       " 234,\n",
       " 236,\n",
       " 238,\n",
       " 240,\n",
       " 242,\n",
       " 244,\n",
       " 246,\n",
       " 248,\n",
       " 250,\n",
       " 252,\n",
       " 254,\n",
       " 256,\n",
       " 258,\n",
       " 260,\n",
       " 262,\n",
       " 264,\n",
       " 266,\n",
       " 268,\n",
       " 270,\n",
       " 272,\n",
       " 274,\n",
       " 276,\n",
       " 278,\n",
       " 280,\n",
       " 282,\n",
       " 284,\n",
       " 286,\n",
       " 288,\n",
       " 290,\n",
       " 292,\n",
       " 294,\n",
       " 296,\n",
       " 298,\n",
       " 300,\n",
       " 302,\n",
       " 304,\n",
       " 306,\n",
       " 308,\n",
       " 310,\n",
       " 312,\n",
       " 314,\n",
       " 316,\n",
       " 318,\n",
       " 320,\n",
       " 322,\n",
       " 324,\n",
       " 326,\n",
       " 328,\n",
       " 330,\n",
       " 332,\n",
       " 334,\n",
       " 336,\n",
       " 338,\n",
       " 340,\n",
       " 342,\n",
       " 344,\n",
       " 346,\n",
       " 348,\n",
       " 350,\n",
       " 352,\n",
       " 354,\n",
       " 356,\n",
       " 358,\n",
       " 360,\n",
       " 362,\n",
       " 364,\n",
       " 366,\n",
       " 368,\n",
       " 370,\n",
       " 372,\n",
       " 374,\n",
       " 376,\n",
       " 378,\n",
       " 380,\n",
       " 382,\n",
       " 384,\n",
       " 386,\n",
       " 388,\n",
       " 390,\n",
       " 392,\n",
       " 394,\n",
       " 396,\n",
       " 398,\n",
       " 400,\n",
       " 402,\n",
       " 404,\n",
       " 406,\n",
       " 408,\n",
       " 410,\n",
       " 412,\n",
       " 414,\n",
       " 416,\n",
       " 418,\n",
       " 420,\n",
       " 422,\n",
       " 424,\n",
       " 426,\n",
       " 428,\n",
       " 430,\n",
       " 432,\n",
       " 434,\n",
       " 436,\n",
       " 438,\n",
       " 440,\n",
       " 442,\n",
       " 444,\n",
       " 446,\n",
       " 448,\n",
       " 450,\n",
       " 452,\n",
       " 454,\n",
       " 456,\n",
       " 458,\n",
       " 460,\n",
       " 462,\n",
       " 464,\n",
       " 466,\n",
       " 468,\n",
       " 470,\n",
       " 472,\n",
       " 474,\n",
       " 476,\n",
       " 478,\n",
       " 480,\n",
       " 482,\n",
       " 484,\n",
       " 486,\n",
       " 488,\n",
       " 490,\n",
       " 492,\n",
       " 494,\n",
       " 496,\n",
       " 498,\n",
       " 500,\n",
       " 502,\n",
       " 504,\n",
       " 506,\n",
       " 508,\n",
       " 510,\n",
       " 512,\n",
       " 514,\n",
       " 516,\n",
       " 518,\n",
       " 520,\n",
       " 522,\n",
       " 524,\n",
       " 526,\n",
       " 528,\n",
       " 530,\n",
       " 532,\n",
       " 534,\n",
       " 536,\n",
       " 538,\n",
       " 540,\n",
       " 542,\n",
       " 544,\n",
       " 546,\n",
       " 548,\n",
       " 550,\n",
       " 552,\n",
       " 554,\n",
       " 556,\n",
       " 558,\n",
       " 560,\n",
       " 562,\n",
       " 564,\n",
       " 566,\n",
       " 568,\n",
       " 570,\n",
       " 572,\n",
       " 574,\n",
       " 576,\n",
       " 578,\n",
       " 580,\n",
       " 582,\n",
       " 584,\n",
       " 586,\n",
       " 588,\n",
       " 590,\n",
       " 592,\n",
       " 594,\n",
       " 596,\n",
       " 598,\n",
       " 600,\n",
       " 602,\n",
       " 604,\n",
       " 606,\n",
       " 608,\n",
       " 610,\n",
       " 612,\n",
       " 614,\n",
       " 616,\n",
       " 618,\n",
       " 620,\n",
       " 622,\n",
       " 624,\n",
       " 626,\n",
       " 628,\n",
       " 630,\n",
       " 632,\n",
       " 634,\n",
       " 636,\n",
       " 638,\n",
       " 640,\n",
       " 642,\n",
       " 644,\n",
       " 646,\n",
       " 648,\n",
       " 650,\n",
       " 652,\n",
       " 654,\n",
       " 656,\n",
       " 658,\n",
       " 660,\n",
       " 662,\n",
       " 664,\n",
       " 666,\n",
       " 668,\n",
       " 670,\n",
       " 672,\n",
       " 674,\n",
       " 676,\n",
       " 678,\n",
       " 680,\n",
       " 682,\n",
       " 684,\n",
       " 686,\n",
       " 688,\n",
       " 690,\n",
       " 692,\n",
       " 694,\n",
       " 696,\n",
       " 698,\n",
       " 700,\n",
       " 702,\n",
       " 704,\n",
       " 706,\n",
       " 708,\n",
       " 710,\n",
       " 712,\n",
       " 714,\n",
       " 716,\n",
       " 718,\n",
       " 720,\n",
       " 722,\n",
       " 724,\n",
       " 726,\n",
       " 728,\n",
       " 730,\n",
       " 732,\n",
       " 734,\n",
       " 736,\n",
       " 738,\n",
       " 740,\n",
       " 742,\n",
       " 744,\n",
       " 746,\n",
       " 748,\n",
       " 750,\n",
       " 752,\n",
       " 754,\n",
       " 756,\n",
       " 758,\n",
       " 760,\n",
       " 762,\n",
       " 764,\n",
       " 766,\n",
       " 768,\n",
       " 770,\n",
       " 772,\n",
       " 774,\n",
       " 776,\n",
       " 778,\n",
       " 780,\n",
       " 782,\n",
       " 784,\n",
       " 786,\n",
       " 788,\n",
       " 790,\n",
       " 792,\n",
       " 794,\n",
       " 796,\n",
       " 798,\n",
       " 800,\n",
       " 802,\n",
       " 804,\n",
       " 806,\n",
       " 808,\n",
       " 810,\n",
       " 812,\n",
       " 814,\n",
       " 816,\n",
       " 818,\n",
       " 820,\n",
       " 822,\n",
       " 824,\n",
       " 826,\n",
       " 828,\n",
       " 830,\n",
       " 832,\n",
       " 834,\n",
       " 836,\n",
       " 838,\n",
       " 840,\n",
       " 842,\n",
       " 844,\n",
       " 846,\n",
       " 848,\n",
       " 850,\n",
       " 852,\n",
       " 854,\n",
       " 856,\n",
       " 858,\n",
       " 860,\n",
       " 862,\n",
       " 864,\n",
       " 866,\n",
       " 868,\n",
       " 870,\n",
       " 872,\n",
       " 874,\n",
       " 876,\n",
       " 878,\n",
       " 880,\n",
       " 882,\n",
       " 884,\n",
       " 886,\n",
       " 888,\n",
       " 890,\n",
       " 892,\n",
       " 894,\n",
       " 896,\n",
       " 898,\n",
       " 900,\n",
       " 902,\n",
       " 904,\n",
       " 906,\n",
       " 908,\n",
       " 910,\n",
       " 912,\n",
       " 914,\n",
       " 916,\n",
       " 918,\n",
       " 920,\n",
       " 922,\n",
       " 924,\n",
       " 926,\n",
       " 928,\n",
       " 930,\n",
       " 932,\n",
       " 934,\n",
       " 936,\n",
       " 938,\n",
       " 940,\n",
       " 942,\n",
       " 944,\n",
       " 946,\n",
       " 948,\n",
       " 950,\n",
       " 952,\n",
       " 954,\n",
       " 956,\n",
       " 958,\n",
       " 960,\n",
       " 962,\n",
       " 964,\n",
       " 966,\n",
       " 968,\n",
       " 970,\n",
       " 972,\n",
       " 974,\n",
       " 976,\n",
       " 978,\n",
       " 980,\n",
       " 982,\n",
       " 984,\n",
       " 986,\n",
       " 988,\n",
       " 990,\n",
       " 992,\n",
       " 994,\n",
       " 996,\n",
       " 998,\n",
       " 1000]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ad0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "eight_values = [y for y in even_values if '8' in str(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "257e6585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 18,\n",
       " 28,\n",
       " 38,\n",
       " 48,\n",
       " 58,\n",
       " 68,\n",
       " 78,\n",
       " 80,\n",
       " 82,\n",
       " 84,\n",
       " 86,\n",
       " 88,\n",
       " 98,\n",
       " 108,\n",
       " 118,\n",
       " 128,\n",
       " 138,\n",
       " 148,\n",
       " 158,\n",
       " 168,\n",
       " 178,\n",
       " 180,\n",
       " 182,\n",
       " 184,\n",
       " 186,\n",
       " 188,\n",
       " 198,\n",
       " 208,\n",
       " 218,\n",
       " 228,\n",
       " 238,\n",
       " 248,\n",
       " 258,\n",
       " 268,\n",
       " 278,\n",
       " 280,\n",
       " 282,\n",
       " 284,\n",
       " 286,\n",
       " 288,\n",
       " 298,\n",
       " 308,\n",
       " 318,\n",
       " 328,\n",
       " 338,\n",
       " 348,\n",
       " 358,\n",
       " 368,\n",
       " 378,\n",
       " 380,\n",
       " 382,\n",
       " 384,\n",
       " 386,\n",
       " 388,\n",
       " 398,\n",
       " 408,\n",
       " 418,\n",
       " 428,\n",
       " 438,\n",
       " 448,\n",
       " 458,\n",
       " 468,\n",
       " 478,\n",
       " 480,\n",
       " 482,\n",
       " 484,\n",
       " 486,\n",
       " 488,\n",
       " 498,\n",
       " 508,\n",
       " 518,\n",
       " 528,\n",
       " 538,\n",
       " 548,\n",
       " 558,\n",
       " 568,\n",
       " 578,\n",
       " 580,\n",
       " 582,\n",
       " 584,\n",
       " 586,\n",
       " 588,\n",
       " 598,\n",
       " 608,\n",
       " 618,\n",
       " 628,\n",
       " 638,\n",
       " 648,\n",
       " 658,\n",
       " 668,\n",
       " 678,\n",
       " 680,\n",
       " 682,\n",
       " 684,\n",
       " 686,\n",
       " 688,\n",
       " 698,\n",
       " 708,\n",
       " 718,\n",
       " 728,\n",
       " 738,\n",
       " 748,\n",
       " 758,\n",
       " 768,\n",
       " 778,\n",
       " 780,\n",
       " 782,\n",
       " 784,\n",
       " 786,\n",
       " 788,\n",
       " 798,\n",
       " 800,\n",
       " 802,\n",
       " 804,\n",
       " 806,\n",
       " 808,\n",
       " 810,\n",
       " 812,\n",
       " 814,\n",
       " 816,\n",
       " 818,\n",
       " 820,\n",
       " 822,\n",
       " 824,\n",
       " 826,\n",
       " 828,\n",
       " 830,\n",
       " 832,\n",
       " 834,\n",
       " 836,\n",
       " 838,\n",
       " 840,\n",
       " 842,\n",
       " 844,\n",
       " 846,\n",
       " 848,\n",
       " 850,\n",
       " 852,\n",
       " 854,\n",
       " 856,\n",
       " 858,\n",
       " 860,\n",
       " 862,\n",
       " 864,\n",
       " 866,\n",
       " 868,\n",
       " 870,\n",
       " 872,\n",
       " 874,\n",
       " 876,\n",
       " 878,\n",
       " 880,\n",
       " 882,\n",
       " 884,\n",
       " 886,\n",
       " 888,\n",
       " 890,\n",
       " 892,\n",
       " 894,\n",
       " 896,\n",
       " 898,\n",
       " 908,\n",
       " 918,\n",
       " 928,\n",
       " 938,\n",
       " 948,\n",
       " 958,\n",
       " 968,\n",
       " 978,\n",
       " 980,\n",
       " 982,\n",
       " 984,\n",
       " 986,\n",
       " 988,\n",
       " 998]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eight_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0a7e2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8,\n",
       "  18,\n",
       "  28,\n",
       "  38,\n",
       "  48,\n",
       "  58,\n",
       "  68,\n",
       "  78,\n",
       "  80,\n",
       "  82,\n",
       "  84,\n",
       "  86,\n",
       "  88,\n",
       "  98,\n",
       "  108,\n",
       "  118,\n",
       "  128,\n",
       "  138,\n",
       "  148,\n",
       "  158,\n",
       "  168,\n",
       "  178,\n",
       "  180,\n",
       "  182,\n",
       "  184,\n",
       "  186,\n",
       "  188,\n",
       "  198,\n",
       "  208,\n",
       "  218,\n",
       "  228,\n",
       "  238,\n",
       "  248,\n",
       "  258,\n",
       "  268,\n",
       "  278,\n",
       "  280,\n",
       "  282,\n",
       "  284,\n",
       "  286,\n",
       "  288,\n",
       "  298,\n",
       "  308,\n",
       "  318,\n",
       "  328,\n",
       "  338,\n",
       "  348,\n",
       "  358,\n",
       "  368,\n",
       "  378,\n",
       "  380,\n",
       "  382,\n",
       "  384,\n",
       "  386,\n",
       "  388,\n",
       "  398,\n",
       "  408,\n",
       "  418,\n",
       "  428,\n",
       "  438,\n",
       "  448,\n",
       "  458,\n",
       "  468,\n",
       "  478,\n",
       "  480,\n",
       "  482,\n",
       "  484,\n",
       "  486,\n",
       "  488,\n",
       "  498,\n",
       "  508,\n",
       "  518,\n",
       "  528,\n",
       "  538,\n",
       "  548,\n",
       "  558,\n",
       "  568,\n",
       "  578,\n",
       "  580,\n",
       "  582,\n",
       "  584,\n",
       "  586,\n",
       "  588,\n",
       "  598,\n",
       "  608,\n",
       "  618,\n",
       "  628,\n",
       "  638,\n",
       "  648,\n",
       "  658,\n",
       "  668,\n",
       "  678,\n",
       "  680,\n",
       "  682,\n",
       "  684,\n",
       "  686,\n",
       "  688,\n",
       "  698,\n",
       "  708,\n",
       "  718,\n",
       "  728,\n",
       "  738,\n",
       "  748,\n",
       "  758,\n",
       "  768,\n",
       "  778,\n",
       "  780,\n",
       "  782,\n",
       "  784,\n",
       "  786,\n",
       "  788,\n",
       "  798,\n",
       "  800,\n",
       "  802,\n",
       "  804,\n",
       "  806,\n",
       "  808,\n",
       "  810,\n",
       "  812,\n",
       "  814,\n",
       "  816,\n",
       "  818,\n",
       "  820,\n",
       "  822,\n",
       "  824,\n",
       "  826,\n",
       "  828,\n",
       "  830,\n",
       "  832,\n",
       "  834,\n",
       "  836,\n",
       "  838,\n",
       "  840,\n",
       "  842,\n",
       "  844,\n",
       "  846,\n",
       "  848,\n",
       "  850,\n",
       "  852,\n",
       "  854,\n",
       "  856,\n",
       "  858,\n",
       "  860,\n",
       "  862,\n",
       "  864,\n",
       "  866,\n",
       "  868,\n",
       "  870,\n",
       "  872,\n",
       "  874,\n",
       "  876,\n",
       "  878,\n",
       "  880,\n",
       "  882,\n",
       "  884,\n",
       "  886,\n",
       "  888,\n",
       "  890,\n",
       "  892,\n",
       "  894,\n",
       "  896,\n",
       "  898,\n",
       "  908,\n",
       "  918,\n",
       "  928,\n",
       "  938,\n",
       "  948,\n",
       "  958,\n",
       "  968,\n",
       "  978,\n",
       "  980,\n",
       "  982,\n",
       "  984,\n",
       "  986,\n",
       "  988,\n",
       "  998]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(i for i in list(i for i in range(1, 1000) if i%2==0) if '8' in str(i))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f07b3",
   "metadata": {},
   "source": [
    "#### Class Notes\n",
    "\n",
    "Always use train test split in any supervised learning problems - including Lasso and Ridge\n",
    "\n",
    "Oversampling and undersampling\n",
    "- what if our data is imbalanced? i.e. diabetes outcomes, cc fraud (hopefully there is an uneven split in the classes)\n",
    "- oversample those populations to get closer to the truth and understand the populations at risk\n",
    "- help build models when we are trying to predict a minority case\n",
    "- OVERSAMPLING - creating new synthetic examples in a minority class youre trying to make predictions about; look at statistical probability distribution function is for the class and reflect that in the synthetic examples\n",
    "- UNDERSAMPLING - delete or merge examples in a majority class (not as common, could only be used on a huge dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e617a17",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "\n",
    "article discusses a naive approach to resampling in which the statistical distribution is not necessarily taken into account.\n",
    "\n",
    "what is resampling? \n",
    "- changing the balance on data that is unbalanced, some classes are over or under represented\n",
    "\n",
    "difference between oversampling and undersampling? \n",
    "- oversampling involves duplicating the minority class\n",
    "- undersampling removing some of the majority class\n",
    "\n",
    "can you use them together?\n",
    "- yes, can produce a more robust model\n",
    "\n",
    "what does fit_resample function do?\n",
    "- generates new examples and fits the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c218a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ec3848",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('../Datasets/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f29b1985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3df1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cba5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes.drop('Outcome', axis=1)\n",
    "y = diabetes['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "#Standardize (can happen before or after split)\n",
    "sc = StandardScaler()\n",
    "X_train_scaler = sc.fit_transform(X_train) \n",
    "X_test_scaler = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e7c3e1",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bce7b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.8.1-py3-none-any.whl (189 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\program files\\anaconda\\lib\\site-packages (from imbalanced-learn) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\program files\\anaconda\\lib\\site-packages (from imbalanced-learn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\program files\\anaconda\\lib\\site-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\program files\\anaconda\\lib\\site-packages (from imbalanced-learn) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\program files\\anaconda\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.2.0)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ed0436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c67ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# resample training data \n",
    "\n",
    "ros=RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaler, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38fe82f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10732/2414288533.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#train using resampled data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "#train using resampled data\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate accuracy (assumes a balanced model)\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_pred = model.predict(X_test_scaler)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "#often see the greatest improvement in recall\n",
    "#can plot confusion matrix from here\n",
    "#can show plotting as well to be more descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e39052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "#print function helps format\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6c3e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9137baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b11ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f2eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Support Vector Machines\n",
    "Goal - find a hyperplane that seperates the data points into different groupd\n",
    "hyperplane - decision boundary that allows us to seperate data classified differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e217a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae14add8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
